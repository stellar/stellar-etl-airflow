name: CI

on:
  pull_request:
    types:
      - opened
      - reopened
      - synchronize
      - closed
    branches:
      - master

jobs:
  pre-commit:
    runs-on: ubuntu-latest
    if: >-
      github.event.pull_request.merged == false &&
      github.event.pull_request.state == 'open'

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - uses: pre-commit/action@v3.0.0

  tests:
    runs-on: ubuntu-latest
    needs: [pre-commit]

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          cat airflow_variables_dev.json | sed -e s/\\/home\\/airflow\\/gcs\\/dags\\/// > airflow_variables_ci.json
          python -m pip install --upgrade pip
          pip install -r requirements-ci.txt

      - name: Init Airflow SQLite database
        run: airflow db init

      - name: Import Airflow variables
        run: airflow variables import airflow_variables_ci.json

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - name: Pytest
        run: pytest dags/

  deploy-to-dev:
    runs-on: ubuntu-latest
    needs: [tests]
    # deploy to dev occurs every time
    # someone submits a pr targeting `master`
    # from a branch at `stellar/stellar-etl-airflow` repo
    if: github.repository == 'stellar/stellar-etl-airflow'
    # known caveats:
    # if there's more than 1 person working
    # in the same file this won't behave nicely

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install google-cloud-storage==2.1.0

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - name: "Set up Cloud SDK"
        uses: "google-github-actions/setup-gcloud@v1"

      - name: Upload files to dev GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET
        env:
          GOOGLE_CLOUD_PROJECT: test-hubble-319619
          BUCKET: us-central1-hubble-1pt5-dev-7db0e004-bucket

      - name: get GKE credentials
        uses: "google-github-actions/get-gke-credentials@v1"
        with:
          cluster_name: "us-central1-hubble-1pt5-dev-7db0e004-gke"
          location: $LOCATION

      - name: Update Airflow variables
        run: >
          gcloud composer environments run $COMPOSER_ENVIRONMENT
          --location $LOCATION
          variables import -- gcsfuse/variables.json
        env:
          COMPOSER_ENVIRONMENT: hubble-1pt5-dev
          LOCATION: us-central1

  promote-to-prod:
    runs-on: ubuntu-latest
    # deploy only occurs when pr is merged
    if: github.event.pull_request.merged == true
    permissions:
      pull-requests: write

    steps:
      - uses: actions/checkout@v3

      - name: Create pull request
        run: >
          gh pr create
          --base release
          --head master
          --title "[PRODUCTION] Update production Airflow environment"
          --body "This PR was auto-generated by GitHub Actions.

          After merged and closed, this PR will trigger an action that updates DAGs, libs and schemas files from prod Airflow."
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
