name: Deploy

on:
  workflow_dispatch:
    inputs:
      envName:
        description: "Deploy Environment"
        default: "dev"
        required: true
        type: choice
        options:
          - dev
          - staging
          - prod

concurrency:
  group: ${{ github.workflow }}-${{ github.ref_protected == 'true' && github.sha || github.ref }}-{{ github.event_name }}
  cancel-in-progress: true

jobs:
  tests:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.12

      - name: Install dependencies
        run: |
          cat airflow_variables_dev.json | sed -e s/\\/home\\/airflow\\/gcs\\/dags\\/// > airflow_variables_ci.json
          python -m pip install --upgrade pip
          pip install -r requirements-ci.txt

      - name: Init Airflow SQLite database
        run: airflow db init

      - name: Import Airflow variables
        run: airflow variables import airflow_variables_ci.json

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - name: Pytest
        run: pytest dags/

  deploy-to-dev:
    if: ${{ github.event.inputs.envName == 'dev' }}
    runs-on: ubuntu-latest
    needs: [tests]
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.12

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install google-cloud-storage==2.18.2

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - name: Upload files to dev GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET
        env:
          GOOGLE_CLOUD_PROJECT: test-hubble-319619
          BUCKET: us-central1-stellar-etl-tes-58aaf371-bucket

      - name: Update Airflow variables
        uses: actions-hub/gcloud@25a6ba65b47384aa1d857e8e684ee15047b7bc71
        env:
          PROJECT_ID: test-hubble-319619
          APPLICATION_CREDENTIALS: "${{ secrets.CREDS_TEST_HUBBLE }}"
          COMPOSER_ENVIRONMENT: stellar-etl-test-composer-2
          LOCATION: us-central1
        with:
          args: >
            components install kubectl && gcloud composer environments run
            $COMPOSER_ENVIRONMENT --location $LOCATION variables import
            -- gcsfuse/actual_mount_path/variables.json

  deploy-to-staging:
    if: ${{ github.event.inputs.envName == 'staging' && github.ref == 'refs/heads/staging' }}
    runs-on: ubuntu-latest
    needs: [tests]

    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.12

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-cloud-storage==2.18.2

      - name: Authenticate to hubble GCP
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093
        with:
          credentials_json: "${{ secrets.CREDS_STAGING_HUBBLE }}"

      - name: Upload files to prod GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET --env staging
        env:
          GOOGLE_CLOUD_PROJECT: staging-hubble
          BUCKET: us-central1-stellar-etl-sta-327f762b-bucket

      - name: Update Airflow variables
        uses: actions-hub/gcloud@25a6ba65b47384aa1d857e8e684ee15047b7bc71
        env:
          PROJECT_ID: staging-hubble
          APPLICATION_CREDENTIALS: "${{ secrets.CREDS_STAGING_HUBBLE }}"
          COMPOSER_ENVIRONMENT: stellar-etl-staging-composer-2
          LOCATION: us-central1
        with:
          args: >
            components install kubectl && gcloud composer environments run
            $COMPOSER_ENVIRONMENT --location $LOCATION variables import
            -- gcsfuse/actual_mount_path/variables.json

  deploy-to-prod:
    if: ${{ github.event.inputs.envName == 'prod' && github.ref == 'refs/heads/master' }}
    runs-on: ubuntu-latest
    needs: [tests]

    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: 3.12

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-cloud-storage==2.18.2

      - name: Authenticate to hubble GCP
        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093
        with:
          credentials_json: "${{ secrets.CREDS_PROD_HUBBLE }}"

      - name: Upload files to prod GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET --env prod
        env:
          GOOGLE_CLOUD_PROJECT: hubble-261722
          BUCKET: us-central1-stellar-etl-com-7f6b70e1-bucket

      - name: Update Airflow variables
        uses: actions-hub/gcloud@25a6ba65b47384aa1d857e8e684ee15047b7bc71
        env:
          PROJECT_ID: hubble-261722
          APPLICATION_CREDENTIALS: "${{ secrets.CREDS_PROD_HUBBLE }}"
          COMPOSER_ENVIRONMENT: stellar-etl-composer-2
          LOCATION: us-central1
        with:
          args: >
            components install kubectl && gcloud composer environments run
            $COMPOSER_ENVIRONMENT --location $LOCATION variables import
            -- gcsfuse/actual_mount_path/variables.json
