name: Deploy

on:
  workflow_dispatch:
    inputs:
      envName:
        description: "Deploy Environment"
        default: "dev"
        required: true
        type: choice
        options:
          - dev
          - prod

jobs:
  tests:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          cat airflow_variables_${{ inputs.envName }}.json | sed -e s/\\/home\\/airflow\\/gcs\\/dags\\/// > airflow_variables_ci.json
          python -m pip install --upgrade pip
          pip install -r requirements-ci.txt

      - name: Init Airflow SQLite database
        run: airflow db init

      - name: Import Airflow variables
        run: airflow variables import airflow_variables_ci.json

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - id: "get-credentials"
        uses: "google-github-actions/get-gke-credentials@v2"
        with:
          cluster_name: "us-central1-test-hubble-43c3e190-gke"
          location: "us-central1"

      - name: Pytest
        run: pytest dags/

  deploy-to-dev:
    if: ${{ github.event.inputs.envName == 'dev' }}
    runs-on: ubuntu-latest
    needs: [tests]
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install google-cloud-storage==2.1.0

      - name: Authenticate to test-hubble GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: "${{ secrets.CREDS_TEST_HUBBLE }}"

      - name: Upload files to dev GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET
        env:
          GOOGLE_CLOUD_PROJECT: test-hubble-319619
          BUCKET: us-central1-test-hubble-43c3e190-bucket

      - name: Update Airflow variables
        uses: actions-hub/gcloud@master
        env:
          PROJECT_ID: test-hubble-319619
          APPLICATION_CREDENTIALS: "${{ secrets.CREDS_TEST_HUBBLE }}"
          COMPOSER_ENVIRONMENT: test-hubble
          LOCATION: us-central1
        with:
          args: >
            components install kubectl && gcloud composer environments run
            $COMPOSER_ENVIRONMENT --location $LOCATION variables import
            -- gcsfuse/actual_mount_path/variables.json

  deploy-to-prod:
    if: ${{ github.event.inputs.envName == 'prod' && github.ref == 'refs/heads/master' }}
    runs-on: ubuntu-latest
    needs: [tests]

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-cloud-storage==2.1.0

      - name: Authenticate to hubble GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: "${{ secrets.CREDS_PROD_HUBBLE }}"

      - name: Upload files to prod GCS bucket
        run: python dags/stellar_etl_airflow/add_files_to_composer.py --bucket $BUCKET --env prod
        env:
          GOOGLE_CLOUD_PROJECT: hubble-261722
          BUCKET: us-central1-hubble-14c4ca64-bucket

      - name: Update Airflow variables
        uses: actions-hub/gcloud@master
        env:
          PROJECT_ID: hubble-261722
          APPLICATION_CREDENTIALS: "${{ secrets.CREDS_PROD_HUBBLE }}"
          COMPOSER_ENVIRONMENT: hubble
          LOCATION: us-central1
        with:
          args: >
            components install kubectl && gcloud composer environments run
            $COMPOSER_ENVIRONMENT --location $LOCATION variables import
            -- gcsfuse/actual_mount_path/variables.json
